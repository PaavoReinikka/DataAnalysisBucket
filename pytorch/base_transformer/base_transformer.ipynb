{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8d6afab19e56b7dab3da794832962c35",
     "grade": false,
     "grade_id": "cell-f5e46023398b0aab",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Translation with transformers.\n",
    "\n",
    "Testing transformer model, which was introduced in the paper [Attention is all you need](https://arxiv.org/pdf/1706.03762.pdf).\n",
    "\n",
    "The implementation is based in the [Annotated transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html) blog post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helpers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename):\n",
    "    try:\n",
    "        torch.save(model.state_dict(), filename)\n",
    "        print('Model saved to %s.' % (filename))\n",
    "    except:\n",
    "        raise Exception('The notebook should be run or validated with skip_training=True.')\n",
    "\n",
    "\n",
    "def load_model(model, filename, device):\n",
    "    model.load_state_dict(torch.load(filename, map_location=lambda storage, loc: storage))\n",
    "    print('Model loaded from %s.' % filename)\n",
    "    model.to(device)\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEEP THIS AS TRUE BY DEFAULT -- WILL SKIP TRAINING DURING VALIDATION.\n",
    "skip_training = True\n",
    "# skip_training = False\n",
    "data_dir = \".\"\n",
    "#device = torch.device('cuda:0')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dbbca8fe9cf0cb1cb20dd200e23cfcb0",
     "grade": false,
     "grade_id": "cell-44cf6f3242607cde",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    # always evaluate on CPU\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d7fd231dc4a3319981678549c38c5d02",
     "grade": false,
     "grade_id": "cell-1f1e529682d7ce6d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Make sure you have the data locally, or modify data utils (see old URL comment).*  \n",
    "\n",
    "If you wish to use the utils for another project, change the hardcoded source in the code or ask me for alternative clean datasets. This translation dataset was provided by Alexander Ilin (larger set also exists, in couple of formats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f04ad11eea93bfc2b77e1b5e7b74f93",
     "grade": false,
     "grade_id": "cell-94d57799bcd1786b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices:  tensor([ 349, 1743,   66, 2422,    5,    1])\n",
      "words:  ils regardent un film . EOS\n"
     ]
    }
   ],
   "source": [
    "# Translation data\n",
    "from data import TranslationDataset, SOS_token, EOS_token, MAX_LENGTH\n",
    "trainset = TranslationDataset(data_dir, train=True)\n",
    "\n",
    "src_seq, tgt_seq = trainset[np.random.choice(len(trainset))]\n",
    "print('indices: ', src_seq)\n",
    "print('words: ', ' '.join(trainset.input_lang.index2word[i.item()] for i in src_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9e4762e32894ed6afcd3b5af8d7777ee",
     "grade": false,
     "grade_id": "cell-86482ed71ea81ed3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## DataLoader\n",
    "\n",
    "The collate function combines source sequences in one tensor `src_seqs` with extra values (at the end) filled with `PADDING_VALUE=0`. To tell the model which elements are padded, we also need to compute the mask `src_mask`.\n",
    "\n",
    "The function also combines target sequences in one tensor `tgt_seqs` but it does it a bit differently:\n",
    "* The resulting tensor is of shape `(max_tgt_seq_length+1, batch_size)`, where `max_tgt_seq_length` is the length of the longest target sequence in the mini-batch.\n",
    "* The first element of each sequence in the resulting tensor is `SOS_token`.\n",
    "* The remaining elements are filled similarly to the source sequences with extra values (at the end) filled with `PADDING_VALUE=0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51df20f688b9b190af9bb01687b5603f",
     "grade": false,
     "grade_id": "collate",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "PADDING_VALUE = 0\n",
    "\n",
    "def collate(list_of_samples):\n",
    "    \"\"\"Merges a list of samples to form a mini-batch.\n",
    "\n",
    "    Args:\n",
    "      list_of_samples is a list of tuples (src_seq, tgt_seq):\n",
    "          src_seq is of shape (src_seq_length)\n",
    "          tgt_seq is of shape (tgt_seq_length)\n",
    "\n",
    "    Returns:\n",
    "      src_seqs of shape (max_src_seq_length, batch_size): Tensor of padded source sequences.\n",
    "      src_mask of shape (max_src_seq_length, batch_size): Boolean tensor showing which elements of the\n",
    "          src_seqs tensor should be ignored in computations (filled with PADDING_VALUE).\n",
    "      tgt_seqs of shape (max_tgt_seq_length+1, batch_size): Tensor of padded target sequences.\n",
    "    \"\"\"\n",
    "    batch_size = len(list_of_samples)\n",
    "    \n",
    "    src_lengths = batch_size*[None]\n",
    "    tgt_lengths = batch_size*[None]\n",
    "    \n",
    "    for index, pair in enumerate(list_of_samples):\n",
    "        src_lengths[index] = len(pair[0])\n",
    "        tgt_lengths[index] = len(pair[1])\n",
    "        \n",
    "    max_src_len = np.max(src_lengths)\n",
    "    max_tgt_len = np.max(tgt_lengths)\n",
    "    \n",
    "    src_seqs = torch.empty((max_src_len,batch_size),dtype=torch.long)\n",
    "    tgt_seqs = torch.empty((max_tgt_len,batch_size),dtype=torch.long)\n",
    "    \n",
    "    i = 0\n",
    "    for s,t in list_of_samples:\n",
    "        src_seqs[:,i] = F.pad(s,pad=[0,max_src_len-len(s)], value=PADDING_VALUE)\n",
    "        tgt_seqs[:,i] = F.pad(t,pad=[0,max_tgt_len-len(t)], value=PADDING_VALUE)\n",
    "        i+=1\n",
    "        \n",
    "    token_col = SOS_token*torch.ones((1, tgt_seqs.size(1)),dtype=torch.long)\n",
    "    tgt_seqs = torch.cat((token_col,tgt_seqs),0)\n",
    "    \n",
    "    src_mask = torch.arange(max_src_len)[:,None] < torch.tensor(src_lengths)[None,:]\n",
    "    \n",
    "    return src_seqs, ~src_mask, tgt_seqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f103d72cfd56ec7f6e42872740b6f395",
     "grade": false,
     "grade_id": "cell-e0a6bbaf21ae2a36",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DataLoader (batch_size=64)\n",
    "trainloader = DataLoader(dataset=trainset, batch_size=64, shuffle=True, collate_fn=collate, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "30b1c849fcf27b18ed5256339d9d57a6",
     "grade": false,
     "grade_id": "cell-63be98428fcdc0b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Encoder block\n",
    "\n",
    "One block of the transformer encoder.\n",
    "* [nn.LayerNorm](https://pytorch.org/docs/stable/nn.html#torch.nn.LayerNorm) to implement the `Norm` layer in the figure\n",
    "* [nn.Dropout](https://pytorch.org/docs/stable/nn.html#torch.nn.Dropout) to implement dropout\n",
    "* [nn.MultiheadAttention](https://pytorch.org/docs/stable/nn.html?highlight=multiheadattention#torch.nn.MultiheadAttention) to implement `Multi-Head Attention`.\n",
    "\n",
    "`Feedforward` is simply an MLP processing each element of the source sequence independently.\n",
    "* one hidden layer with `n_hidden` neurons\n",
    "* a dropout and ReLU activation after the hidden layer\n",
    "* an output layer with `n_features` outputs.\n",
    "\n",
    "\n",
    "* Using dropout in both skip connections of the encoder block.\n",
    "\n",
    "(*slightly different to the [Annotated transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html) code*)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16fbfeb035056c0c0d8bde1c1c406fba",
     "grade": false,
     "grade_id": "EncoderBlock",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_features, n_hidden, dropout = 0.1):\n",
    "        super().__init__() \n",
    "        self.linear1 = nn.Linear(n_features, n_hidden)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(n_hidden, n_features)\n",
    "    def forward(self, x):\n",
    "        x = self.drop(F.relu(self.linear1(x)))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, n_features, n_heads, n_hidden=64, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          n_features: Number of input and output features.\n",
    "          n_heads: Number of attention heads in the Multi-Head Attention.\n",
    "          n_hidden: Number of hidden units in the Feedforward (MLP) block.\n",
    "          dropout: Dropout rate after the first layer of the MLP and in two places on the main path (before\n",
    "                   combining the main path with a skip connection).\n",
    "        \"\"\"\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        # NOTE: the redundancy in drop,skip layers is for clarity when coding the block\n",
    "        self.norm1 = nn.LayerNorm(n_features, eps=1e-6)\n",
    "        self.norm2 = nn.LayerNorm(n_features, eps=1e-6)\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "        self.skip1 = nn.Identity()\n",
    "        self.skip2 = nn.Identity()\n",
    "        self.attn = nn.MultiheadAttention(embed_dim= n_features, num_heads=n_heads)\n",
    "        self.ff = FeedForward(n_features, n_hidden, dropout)\n",
    "        \n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x of shape (max_seq_length, batch_size, n_features): Input sequences.\n",
    "          mask of shape (batch_size, max_seq_length): Boolean tensor indicating which elements of the input\n",
    "              sequences should be ignored.\n",
    "        \n",
    "        Returns:\n",
    "          z of shape (max_seq_length, batch_size, n_features): Encoded input sequence.\n",
    "        \"\"\"\n",
    "        x0 = self.skip1(x)\n",
    "        x,_ = self.attn(x,x,x, mask)\n",
    "        x = self.norm1(x0 + self.drop1(x))\n",
    "        x1 = self.skip2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.norm2(x1 + self.drop2(x))\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5b121062b3d9db25b2cf16db2bc28af9",
     "grade": false,
     "grade_id": "cell-e2776b50381263dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "## Encoder\n",
    "\n",
    "The encoder is a stack of the following blocks:\n",
    "* Embedding of words (please use [nn.Embedding](https://pytorch.org/docs/stable/nn.html#torch.nn.Embedding))\n",
    "* Positional encoding.\n",
    "* `n_blocks` of the `EncoderBlock` modules.\n",
    "\n",
    "Notes:\n",
    "* The `PositionalEncoding` is the same as in [Annotated transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html) blog post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0036f01e993194d6a37f507e49ff7099",
     "grade": false,
     "grade_id": "Encoder",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from copy import deepcopy\n",
    "def clones(module, N):\n",
    "    \"Produce N identical blocks.\"\n",
    "    return nn.ModuleList([deepcopy(module) for _ in range(N)])\n",
    "'''\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"This implementation is the same as in the Annotated transformer blog post\n",
    "        See https://nlp.seas.harvard.edu/2018/04/03/attention.html for more detail.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        assert (d_model % 2) == 0, 'The embedding dim should be an even number.'\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class PEEmbed(nn.Module):\n",
    "    def __init__(self, src_vocab_size, n_features, dropout=0.1):\n",
    "        super(PEEmbed, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(src_vocab_size, n_features)\n",
    "        self.pe = PositionalEncoding(n_features, dropout, MAX_LENGTH)\n",
    "        \n",
    "    def forward(self, pad_seqs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          pad_seqs of shape (max_seq_length, batch_size): Padded source sequences.\n",
    "          seq_lengths: List of sequence lengths.\n",
    "          hidden of shape (1, batch_size, hidden_size): Initial states of the GRU.\n",
    "\n",
    "        Returns:\n",
    "          outputs of shape (max_seq_length, batch_size, hidden_size): Padded outputs of GRU at every step.\n",
    "          hidden of shape (1, batch_size, hidden_size): Updated states of the GRU.\n",
    "        \"\"\"\n",
    "        pee = self.pe(self.embedding(pad_seqs))\n",
    "        return pee\n",
    "\n",
    "        \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, src_vocab_size, n_blocks, n_features, n_heads, n_hidden=64, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          src_vocab_size: Number of words in the source vocabulary.\n",
    "          n_blocks: Number of EncoderBlock blocks.\n",
    "          n_features: Number of features to be used for word embedding and further in all layers of the encoder.\n",
    "          n_heads: Number of attention heads inside the EncoderBlock.\n",
    "          n_hidden: Number of hidden units in the Feedforward block of EncoderBlock.\n",
    "          dropout: Dropout level used in EncoderBlock.\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        self.pee = PEEmbed(src_vocab_size, n_features, dropout)\n",
    "        #self.blocks = clones(EncoderBlock(n_features, n_heads, n_hidden, dropout),n_blocks)\n",
    "        self.blocks = nn.ModuleList([EncoderBlock(n_features, n_heads, n_hidden, dropout) \\\n",
    "                                     for _ in range(n_blocks)])\n",
    "        \n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x of shape (max_seq_length, batch_size): LongTensor with the input sequences.\n",
    "          mask of shape (batch_size, max_seq_length): BoolTensor indicating which elements should be ignored.\n",
    "        \n",
    "        Returns:\n",
    "          z of shape (max_seq_length, batch_size, n_features): Encoded input sequence.\n",
    "        \"\"\"\n",
    "        x = self.pee(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x, mask)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c59d3e8bf698511a855df8b7fbc04491",
     "grade": false,
     "grade_id": "cell-102038af7faba64b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aea4e7f9885ee84d12e6ab183ffa4c45",
     "grade": false,
     "grade_id": "cell-3133e50590987e56",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Subsequent mask\n",
    "\n",
    "In the training loop, target sequences (starting with `SOS_token`) are passed as inputs for the decoder. Doing that allows the decoder to use previously decoded words when predicting probabilities of the next word. \n",
    "\n",
    "During decoding, we need to make sure that when we compute the probability of the next word, we only use preceding and not subsequent words. This is can be done by masking the \"unseen\" data.\n",
    "\n",
    "The $i$-th row in the produced mask says which of the input elements should be used to compute the $i$-th element of the output:\n",
    "* `0`: the corresponding element of the input sequence can be used.\n",
    "* `-inf`: the corresponding element of the input sequence cannot be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c91dbc90b6c803baeffb280bbf39324b",
     "grade": false,
     "grade_id": "cell-c2dfee9a9f2d674e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1).float()\n",
    "    mask = mask.masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20d6d1ff1df0c0609a1cfc1954e4e94c",
     "grade": false,
     "grade_id": "cell-ec36a7f1884b54f0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2e2fea5e660>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To get the idea of the mask\n",
    "mask = subsequent_mask(10)\n",
    "print(mask)\n",
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e8db968d0d9c4b5706ab23917e54237f",
     "grade": false,
     "grade_id": "cell-c26c4a8fecf141bd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Decoder block\n",
    "\n",
    "* [nn.LayerNorm](https://pytorch.org/docs/stable/nn.html#torch.nn.LayerNorm) to implement the `Norm` layer in the figure\n",
    "* [nn.Dropout](https://pytorch.org/docs/stable/nn.html#torch.nn.Dropout) to implement dropout\n",
    "* [nn.MultiheadAttention](https://pytorch.org/docs/stable/nn.html?highlight=multiheadattention#torch.nn.MultiheadAttention) to implement `Multi-Head Attention`.\n",
    "\n",
    "`Feedforward` is again simply an MLP processing each position. The model seems to do fine with fairly simple implementation.\n",
    "  * one hidden layer with `n_hidden` neurons\n",
    "  * a dropout and ReLU activation after the hidden layer\n",
    "  * an output layer with `n_features` outputs.\n",
    "\n",
    "* where skip connections are used, dropout is applied on the main path, and then (after combining) layer normalization is applied. This order is slightly different to the [Annotated transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html) code.\n",
    "\n",
    "Notes:\n",
    "* The first attention block is self-attention when query, key and value inputs are same. The second attention block uses the encoded `z` values as keys and values, and the outputs of the previous layer as query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac34dc6cc4b47a9adcd2e4990e6e536f",
     "grade": false,
     "grade_id": "DecoderBlock",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, n_features, n_heads, n_hidden=64, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          n_features: Number of input and output features.\n",
    "          n_heads: Number of attention heads in the Multi-Head Attention.\n",
    "          n_hidden: Number of hidden units in the Feedforward (MLP) block.\n",
    "          dropout: Dropout rate after the first layer of the MLP and in three places on the main path (before\n",
    "                   combining the main path with a skip connection).\n",
    "        \"\"\"\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(n_features, eps=1e-6)\n",
    "        self.norm2 = nn.LayerNorm(n_features, eps=1e-6)\n",
    "        self.norm3 = nn.LayerNorm(n_features, eps=1e-6)\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "        self.drop3 = nn.Dropout(dropout)\n",
    "        self.skip1 = nn.Identity()\n",
    "        self.skip2 = nn.Identity()\n",
    "        self.skip3 = nn.Identity()\n",
    "        self.attn1 = nn.MultiheadAttention(embed_dim= n_features, num_heads=n_heads)\n",
    "        self.attn2 = nn.MultiheadAttention(embed_dim= n_features, num_heads=n_heads)\n",
    "        self.ff = FeedForward(n_features, n_hidden, dropout)\n",
    "\n",
    "    def forward(self, y, z, src_mask, tgt_mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          y of shape (max_tgt_seq_length, batch_size, n_features): Transformed target sequences used as the inputs\n",
    "              of the block.\n",
    "          z of shape (max_src_seq_length, batch_size, n_features): Encoded source sequences (outputs of the\n",
    "              encoder).\n",
    "          src_mask of shape (batch_size, max_src_seq_length): Boolean tensor indicating which elements of the\n",
    "             source sequences should be ignored.\n",
    "          tgt_mask of shape (max_tgt_seq_length, max_tgt_seq_length): Subsequent mask to ignore subsequent\n",
    "             elements of the target sequences in the inputs. The rows of this matrix correspond to the output\n",
    "             elements and the columns correspond to the input elements.\n",
    "        \n",
    "        Returns:\n",
    "          z of shape (max_seq_length, batch_size, n_features): Output tensor.\n",
    "        \"\"\"\n",
    "        y0 = self.skip1(y)\n",
    "        y,_ = self.attn1(y, y, y, attn_mask= tgt_mask)\n",
    "        y = self.norm1(y0 + self.drop1(y))\n",
    "        y1 = self.skip2(y)\n",
    "        y,_ = self.attn2(y,z,z,key_padding_mask= src_mask)\n",
    "        y = self.norm2(y1 + self.drop2(y))\n",
    "        y2 = self.skip3(y)\n",
    "        y = self.ff(y)\n",
    "        y = self.norm3(y2 + self.drop3(y))\n",
    "        \n",
    "        return y\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b4af57790480337233da05440de8d44c",
     "grade": false,
     "grade_id": "cell-a30448f3b22189c6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "## Decoder\n",
    "\n",
    "The decoder is a stack of the following blocks:\n",
    "* Embedding of words (please use [nn.Embedding](https://pytorch.org/docs/stable/nn.html#torch.nn.Embedding))\n",
    "* Positional encoding (please use `tr.PositionalEncoding` from the attached module)\n",
    "* `n_blocks` of the `DecoderBlock` modules.\n",
    "* A linear layer with `tgt_vocab_size` output features.\n",
    "* Log_softmax nonlinearity.\n",
    "\n",
    "Note: our longest sequences have length `MAX_LENGTH`, (specify for `PositionalEncoding`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3df85963aad70f47f6ab05ab5141959d",
     "grade": false,
     "grade_id": "Decoder",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, tgt_vocab_size, n_blocks, n_features, n_heads, n_hidden=64, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          tgt_vocab_size: Number of words in the target vocabulary.\n",
    "          n_blocks: Number of EncoderBlock blocks.\n",
    "          n_features: Number of features to be used for word embedding and further in all layers of the decoder.\n",
    "          n_heads: Number of attention heads inside the DecoderBlock.\n",
    "          n_hidden: Number of hidden units in the Feedforward block of DecoderBlock.\n",
    "          dropout: Dropout level used in DecoderBlock.\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        self.pee = PEEmbed(tgt_vocab_size, n_features, dropout)\n",
    "        #self.blocks = clones(DecoderBlock(n_features, n_heads, n_hidden, dropout),n_blocks)\n",
    "        self.blocks = nn.ModuleList([DecoderBlock(n_features, n_heads, n_hidden, dropout) for _ in range(n_blocks)])\n",
    "        self.linear = nn.Linear(n_features, tgt_vocab_size)\n",
    "        \n",
    "    def forward(self, y, z, src_mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          y of shape (max_tgt_seq_length, batch_size): Transformed target sequences used as the inputs\n",
    "              of the block.\n",
    "          z of shape (max_src_seq_length, batch_size, n_features): Encoded source sequences (outputs of the\n",
    "              encoder).\n",
    "          src_mask of shape (batch_size, max_src_seq_length): Boolean tensor indicating which elements of the\n",
    "             source sequences should be ignored.\n",
    "        \n",
    "        Returns:\n",
    "          out of shape (max_seq_length, batch_size, tgt_vocab_size): Log-softmax probabilities of the words\n",
    "              in the output sequences.\n",
    "        \"\"\"\n",
    "        dev = y.device\n",
    "        tgt_mask = subsequent_mask(y.size(0)).to(device)\n",
    "        y = self.pee(y)\n",
    "        for block in self.blocks:\n",
    "            y = block(y, z, src_mask, tgt_mask)\n",
    "        out = self.linear(y)\n",
    "        \n",
    "        return F.log_softmax(out, dim=2)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ac142e2969764fa1e646091bf0255a7a",
     "grade": false,
     "grade_id": "cell-10c28584fb58b386",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Model init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "21ab3ba0364f3ec7e43d3204c702e831",
     "grade": false,
     "grade_id": "cell-ec608760ebfa7f8e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (pee): PEEmbed(\n",
       "    (embedding): Embedding(2925, 256)\n",
       "    (pe): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0-2): 3 x DecoderBlock(\n",
       "      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "      (drop1): Dropout(p=0.1, inplace=False)\n",
       "      (drop2): Dropout(p=0.1, inplace=False)\n",
       "      (drop3): Dropout(p=0.1, inplace=False)\n",
       "      (skip1): Identity()\n",
       "      (skip2): Identity()\n",
       "      (skip3): Identity()\n",
       "      (attn1): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (attn2): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=256, out_features=2925, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the transformer model\n",
    "n_features = 256\n",
    "encoder = Encoder(src_vocab_size=trainset.input_lang.n_words, n_blocks=3, n_features=n_features,\n",
    "                  n_heads=16, n_hidden=1024)\n",
    "decoder = Decoder(tgt_vocab_size=trainset.output_lang.n_words, n_blocks=3, n_features=n_features,\n",
    "                  n_heads=16, n_hidden=1024)\n",
    "\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7797d6c950c67652f64789f70d9a050",
     "grade": false,
     "grade_id": "cell-b1645c0797a9d5f6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Optimizer\n",
    "\n",
    "Testing the `NoamOptimizer`. Standard optimizers like Adam, are more prone to hitting plateaus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoamOptimizer:\n",
    "    \"\"\"\n",
    "    Optim wrapper that implements rate.\n",
    "    The learning rate is defined by the model size, the warmup and the step.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "        \n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        Update parameters and rate.\n",
    "        \"\"\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def rate(self, step = None):\n",
    "        \"\"\"\n",
    "        Implement `lrate` above\n",
    "        \"\"\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return self.factor * \\\n",
    "            (self.model_size ** (-0.5) *\n",
    "            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        self.optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5e9e6a3f67af78c11dd7b4785d80731",
     "grade": false,
     "grade_id": "cell-3dcb8dddc9bd9ee7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "parameters = list(encoder.parameters()) + list(decoder.parameters())\n",
    "adam = torch.optim.Adam(parameters, lr=0, betas=(0.9, 0.98), eps=1e-9)\n",
    "optimizer = NoamOptimizer(n_features, 2, 10000, adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "324942900c9447302b13235d20ba48ec",
     "grade": false,
     "grade_id": "cell-8a12754e13e91bef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "trainloader = DataLoader(dataset=trainset, batch_size=64, shuffle=True, collate_fn=collate, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the training loop, we first encode source sequences using the encoder. Then we decode the encoded sequences by the decoder which also receives shifted target sequences as inputs. The decoder outputs a tensor that contains log-softmax probabilities of words in the output language.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6270848f5387bf01aba9bb5f50303a78",
     "grade": false,
     "grade_id": "training_loop",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if not skip_training:\n",
    "    n_epochs = 40\n",
    "    for i in range(n_epochs):\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        epoch_loss = []\n",
    "\n",
    "        for s, s_mask_T, t in trainloader:\n",
    "            s = s.to(device)\n",
    "            t = t.to(device)\n",
    "            s_mask = s_mask_T.transpose(0,1).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            z = encoder(s, s_mask)\n",
    "            yhat = decoder(t[:-1],z, s_mask)\n",
    "            loss = F.nll_loss(yhat.permute(1,2,0),t[1:].permute(1,0),\\\n",
    "                                  ignore_index=0, reduction = 'mean')#, reduce=True,size_average=True)\n",
    "\n",
    "            epoch_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(np.mean(epoch_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08580f112f8d4db725e98728207e7e26",
     "grade": false,
     "grade_id": "accuracy",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from tr_encoder.pth.\n",
      "Model loaded from tr_decoder.pth.\n"
     ]
    }
   ],
   "source": [
    "if not skip_training:\n",
    "    save_model(encoder, 'tr_encoder.pth')\n",
    "    save_model(decoder, 'tr_decoder.pth')\n",
    "else:\n",
    "    encoder = Encoder(src_vocab_size=trainset.input_lang.n_words, n_blocks=3, n_features=256, n_heads=16, n_hidden=1024)\n",
    "    load_model(encoder, 'tr_encoder.pth', device)\n",
    "    \n",
    "    decoder = Decoder(tgt_vocab_size=trainset.output_lang.n_words, n_blocks=3, n_features=256, n_heads=16, n_hidden=1024)\n",
    "    load_model(decoder, 'tr_decoder.pth', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e17b377e3dc43691624258b933fbbcee",
     "grade": false,
     "grade_id": "cell-25e4072e5588afaa",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Generate translations with the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98d0db2a273b0d26f3464d1e1e640d11",
     "grade": false,
     "grade_id": "cell-2122447b9917f9b6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def translate(encoder, decoder, src_seq):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      encoder (Encoder): Trained encoder.\n",
    "      decoder (Decoder): Trained decoder.\n",
    "      src_seq of shape (src_seq_length): LongTensor of word indices of the source sentence.\n",
    "    \n",
    "    Returns:\n",
    "      out_seq of shape (out_seq_length, 1): LongTensor of word indices of the output sentence.\n",
    "    \"\"\"\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    src_seq = src_seq.view(-1,1)\n",
    "    src_mask = (src_seq==EOS_token).view(1,-1)\n",
    "    memory = encoder(src_seq, src_mask)\n",
    "    \n",
    "    prev_words = SOS_token*torch.ones(1, 1).type_as(src_seq.data)\n",
    "    for i in range(MAX_LENGTH):\n",
    "        prob = decoder(prev_words, memory, src_mask)\n",
    "        _, next_word = torch.max(prob, dim = 2)\n",
    "        next_word = next_word.data[i]\n",
    "        prev_words = torch.cat([prev_words,next_word*torch.ones(1, 1).type_as(src_seq.data)], dim=0)\n",
    "        \n",
    "        if next_word==EOS_token:\n",
    "            break\n",
    "    \n",
    "    return prev_words[1:]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ccd8f4bdf1f0deb26e2d19f063153ae9",
     "grade": false,
     "grade_id": "cell-22b623f5d5351a41",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Below, we translate sentences from the *training* set. The translations look ~similar to the target sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0b9887d55695ce56e65b6d850af37578",
     "grade": false,
     "grade_id": "cell-9fba1fede2232e76",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate training data:\n",
      "-----------------------------\n",
      "> je n en suis pas fier . EOS\n",
      "= i m not proud of that . EOS\n",
      "< i m not proud of this . EOS \n",
      "\n",
      "> nous sommes tous deux ecrivains . EOS\n",
      "= we re both writers . EOS\n",
      "< we re both writers . EOS \n",
      "\n",
      "> elle est toujours habillee en noir . EOS\n",
      "= she is always dressed in black . EOS\n",
      "< she is always dressed in black . EOS \n",
      "\n",
      "> je te vois sous un nouveau jour . EOS\n",
      "= i m seeing you in a new light . EOS\n",
      "< i m seeing you in a new light . EOS \n",
      "\n",
      "> vous avez parfaitement raison . EOS\n",
      "= you re absolutely right . EOS\n",
      "< you re totally right . EOS \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Translate training data:')\n",
    "print('-----------------------------')\n",
    "for i in range(5):\n",
    "    src_sentence, tgt_sentence = trainset[np.random.choice(len(trainset))]\n",
    "    print('>', ' '.join(trainset.input_lang.index2word[i.item()] for i in src_sentence))\n",
    "    print('=', ' '.join(trainset.output_lang.index2word[i.item()] for i in tgt_sentence))\n",
    "    out_sentence = translate(encoder, decoder, src_sentence)\n",
    "    print('<', ' '.join(trainset.output_lang.index2word[i.item()] for i in out_sentence), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd0798d4f5e481ff8449925b3c934ea7",
     "grade": false,
     "grade_id": "cell-a8c5476c494b3dea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now sentences from the test set. The translations are typically\n",
    "worse than for the training sequences but they still look reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f268ad9539d79bc2af8e349a2a94ff99",
     "grade": false,
     "grade_id": "cell-e27f5e4329673f0d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "testset = TranslationDataset(data_dir, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df287dda075179fd01021a51c75a1607",
     "grade": false,
     "grade_id": "cell-c1cafaf3ca027d6d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate test data:\n",
      "-----------------------------\n",
      "> je suis reellement fier de toi . EOS\n",
      "= i m really proud of you . EOS\n",
      "< i m really proud of you . EOS \n",
      "\n",
      "> elle est un peu niaise . EOS\n",
      "= she s a bit naive . EOS\n",
      "< she s a bit jealous . EOS \n",
      "\n",
      "> nous sommes cousines . EOS\n",
      "= we re cousins . EOS\n",
      "< we re the owners . EOS \n",
      "\n",
      "> nous n en sommes pas si sures . EOS\n",
      "= we re not so sure . EOS\n",
      "< we re not so so sure . EOS \n",
      "\n",
      "> tu es partiale . EOS\n",
      "= you re biased . EOS\n",
      "< you re clever . EOS \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Translate test data:')\n",
    "print('-----------------------------')\n",
    "for i in range(5):\n",
    "    input_sentence, target_sentence = testset[np.random.choice(len(testset))]\n",
    "    print('>', ' '.join(testset.input_lang.index2word[i.item()] for i in input_sentence))\n",
    "    print('=', ' '.join(testset.output_lang.index2word[i.item()] for i in target_sentence))\n",
    "    output_sentence = translate(encoder, decoder, input_sentence)\n",
    "    print('<', ' '.join(testset.output_lang.index2word[i.item()] for i in output_sentence), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
